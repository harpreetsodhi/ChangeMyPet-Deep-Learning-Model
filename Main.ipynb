{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+Zn7CbpcvV+xIMluo7ftB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harpreetsodhi/ChangeMyPet-Deep-Learning-Model/blob/master/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5JDwHSaWgkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rKgBjrwWpL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained=True).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e82Y4BhJWt4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = torch.hub.load('pytorch/vision:v0.6.0', 'fcn_resnet101', pretrained=True).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XClEknG2Wy1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThN54_CuW08n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone \"https://github.com/harpreetsodhi/ChangeMyPet-Deep-Learning-Model.git\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e2MemT1XHAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image, ImageOps\n",
        "from torchvision import transforms\n",
        "\n",
        "input_image = Image.open('/content/dog_translate.png')\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(512),\n",
        "    transforms.CenterCrop(512),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(input_image)\n",
        "\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "    model2.to('cuda')\n",
        "# ouput_original_image = output.argmax(0).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk4fGBAPXMfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from changemypet.src.biggan import BigGAN512\n",
        "import torch \n",
        "import torchvision\n",
        "from scipy.stats import truncnorm\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvo0oOoCXPs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "truncation = torch.clamp(torch.tensor(0.4), min=0.02+1e-4, max=1.0-1e-4).float()  # truncation is 0.4\n",
        "c = torch.tensor((207,)).long()  # class_label is 260\n",
        "z = truncation * torch.as_tensor(truncnorm.rvs(-2.0, 2.0, size=(1, 128),random_state=18)).float()\n",
        "z.requires_grad = True\n",
        "\n",
        "biggan = BigGAN512()\n",
        "\n",
        "biggan.load_state_dict(torch.load(\"/content/drive/My Drive/biggan512-release.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzXa6DdiXUZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softXEnt (input, target ):\n",
        "    logprobs = torch.nn.functional.log_softmax (input, dim = 0)\n",
        "    return  -(target * logprobs).sum() / (input.shape[1]*input.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aydd-xSnXWkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MSE_Loss (input, target):\n",
        "  loss = torch.nn.MSELoss()\n",
        "  return loss(input, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTNnCtUQXZ8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biggan.eval()\n",
        "img = biggan(z, c, truncation.item())\n",
        "pil = torchvision.transforms.ToPILImage()((0.5 * (img.data + 1)).squeeze())\n",
        "import PIL\n",
        "# pil=ImageOps.mirror(pil)\n",
        "# pil=pil.transpose(PIL.Image.ROTATE_90)\n",
        "plt.imshow(pil)\n",
        "# pil.save(\"dog_translate.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MVtRTEJXdXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biggan.eval()\n",
        "# optimizer = torch.optim.AdamW([z], lr=0.1)\n",
        "optimizer = torch.optim.Adam([z], lr=1e-1, betas=(0.5, 0.999))\n",
        "\n",
        "# create a color pallette, selecting a color for each class\n",
        "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
        "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
        "colors = (colors % 255).numpy().astype(\"uint8\")\n",
        "\n",
        "for i in range(10):\n",
        "    with torch.enable_grad():\n",
        "        optimizer.zero_grad()\n",
        "        img = biggan(z, c, truncation.item())\n",
        "        \n",
        "        #Segmentation of Predicted Img\n",
        "        output_predicted_image_1 = model(0.5 * (img.cuda() + 1))['out'][0]\n",
        "        output_predicted_image_2 = model2(0.5 * (img.cuda() + 1))['out'][0]\n",
        "        \n",
        "        #applying softmax on predicted imgs segmaps\n",
        "        output_predicted_image_1_s = torch.nn.functional.softmax (output_predicted_image_1, dim = 0) #softmax o_P1\n",
        "        output_predicted_image_2_s = torch.nn.functional.softmax (output_predicted_image_2, dim = 0) #softmax o_P2\n",
        "        \n",
        "        #take average of 2 predicted img segmaps\n",
        "        output_p = (output_predicted_image_1_s + output_predicted_image_2_s)/2  # softmax_predicted_output_average\n",
        "        \n",
        "        #Segmentation of Original Img\n",
        "        output_original_image_1 = model(input_batch)['out'][0]\n",
        "        output_original_image_2 = model2(input_batch)['out'][0]\n",
        "        \n",
        "        #applying softmax on original imgs segmaps\n",
        "        output_original_image_1_s=torch.nn.functional.softmax (output_original_image_1, dim = 0) #softmax o_o_1\n",
        "        output_original_image_2_s=torch.nn.functional.softmax (output_original_image_2, dim = 0) #softmax o_o_2\n",
        "        \n",
        "        #take average of 2 original img segmaps\n",
        "        output_o = (output_original_image_1_s + output_original_image_2_s)/2 # softmax_original_output_average\n",
        "        # output_o = output_o[12]\n",
        "\n",
        "        # Target image segmaps\n",
        "        # target = torch.nn.functional.softmax (output_o[[0,12]], dim = 0) # softmax on the target \n",
        "        target = output_o[12]\n",
        "\n",
        "        # seg_1 = torch.nn.functional.softmax (output_predicted_image_1_s[[12]], dim = 0) # softmax on the target \n",
        "        # seg_2 = torch.nn.functional.softmax (output_predicted_image_2_s[[12]], dim = 0) # softmax on the target \n",
        "        seg_1 = output_predicted_image_1_s[12]\n",
        "        seg_2 = output_predicted_image_2_s[12]\n",
        "\n",
        "        loss1 = MSE_Loss(seg_1, target)\n",
        "        loss2 = MSE_Loss(seg_1, target)\n",
        "\n",
        "        cost_x = (loss1 + loss2 ) / 2 \n",
        "\n",
        "        print(\"Epoch : \",i+1)\n",
        "        print(\"Loss  : \", cost_x.item())\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(10,5))\n",
        "    plt.subplots_adjust(left = 0.125,right = 0.9,top=0.9,bottom = 0.1,wspace = 0.3,hspace = 0.2)\n",
        "\n",
        "    ax1 = fig.add_subplot(241)\n",
        "    ax1.title.set_text('Original Image')\n",
        "    plt.imshow(input_image)\n",
        "\n",
        "    ax2 = fig.add_subplot(242)\n",
        "    ax2.title.set_text('O_Seg_map 1')\n",
        "    r = Image.fromarray(model(input_batch)['out'][0].argmax(0).float().byte().cpu().numpy())#.resize(input_image.size)\n",
        "    r.putpalette(colors)\n",
        "    plt.imshow(r)\n",
        "     \n",
        "    ax3 = fig.add_subplot(243)\n",
        "    ax3.title.set_text('O_Seg_Map 2')\n",
        "    r = Image.fromarray(model2(input_batch)['out'][0].argmax(0).float().byte().cpu().numpy())#.resize(input_image.size)\n",
        "    r.putpalette(colors)\n",
        "    plt.imshow(r)\n",
        "\n",
        "    ax4 = fig.add_subplot(244)\n",
        "    ax4.title.set_text('O_Avg Seg_Map')\n",
        "    r = Image.fromarray(output_o.argmax(0).float().byte().cpu().numpy())\n",
        "    r.putpalette(colors)\n",
        "    plt.imshow(r)\n",
        "\n",
        "    ax5 = fig.add_subplot(245)\n",
        "    ax5.title.set_text('Generated Image')\n",
        "    pil = torchvision.transforms.ToPILImage()((0.5 * (img.data + 1)).squeeze())\n",
        "    plt.imshow(pil)\n",
        "\n",
        "    ax6 = fig.add_subplot(246)\n",
        "    ax6.title.set_text('G_Seg_map 1')\n",
        "    r = Image.fromarray(output_predicted_image_1.argmax(0).float().byte().cpu().numpy())\n",
        "    r.putpalette(colors)\n",
        "    plt.imshow(r)\n",
        "\n",
        "    ax7 = fig.add_subplot(247)\n",
        "    ax7.title.set_text('G_Seg_Map 2')\n",
        "    r = Image.fromarray(output_predicted_image_2.argmax(0).float().byte().cpu().numpy())\n",
        "    r.putpalette(colors)\n",
        "    plt.imshow(r)\n",
        "\n",
        " \n",
        "    ax8 = fig.add_subplot(248)\n",
        "    ax8.title.set_text('G_Avg Seg_Map')\n",
        "    r = Image.fromarray(output_p.argmax(0).float().byte().cpu().numpy())\n",
        "    r.putpalette(colors)\n",
        "    plt.imshow(r)\n",
        "    plt.show()\n",
        "\n",
        "    print('-'*100)\n",
        "    cost_x.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print('End')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}